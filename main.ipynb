{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tugas Besar IF3270 Pembelajaran Mesin Artificial Neural Network\n",
    "\n",
    "### Bagian B: Implementasi Mini-Batch Gradient Descent untuk Feed Forward Neural Network\n",
    "Jaringan saraf tiruan pada bagian feed forward neural network (FFNN) menggunakan bahasa python.\n",
    "\n",
    "### Kelompok 1\n",
    "- 13520004 Gede Prasidha Bhawarnawa\n",
    "- 13521076 Moh. Aghna Maysan Abyan\n",
    "- 13521110 Yanuar Sano Nur Rasyid\n",
    "- 13521152 Muhammad Naufal Nalendra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fungsi aktivasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax Activation Function Implementation\n",
    "def softmax(arr):\n",
    "    arr = np.array(arr)\n",
    "    arr = np.exp(arr)\n",
    "    sum_arr = np.sum(arr)\n",
    "    return arr/sum_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid Activation Function Implementation\n",
    "def sigmoid(arr):\n",
    "    numerator = np.exp(arr)\n",
    "    denominator = numerator + 1\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Activation Function Implementation\n",
    "def linear(arr):\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rectified Linear Unit (ReLU) Activation Function Implementation\n",
    "def relu(val):\n",
    "    if val < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countSSError(results, expected_results):\n",
    "    results = np.array(results)\n",
    "    expected_results = np.array(expected_results)\n",
    "    if results.shape != expected_results.shape:\n",
    "        print(\"Error: array shape mismatch\")\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        return np.sum(np.square(results - expected_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derivatif (turunan) fungsi aktivasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative_relu(val):\n",
    "    if val < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative_sigmoid(val):\n",
    "    return val * (1 - val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative_linear(val):\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivativeSoftmax(value, isTrueClass):\n",
    "    if isTrueClass:\n",
    "        return -1 * (1 - value)\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative_error_sse(target, output):\n",
    "    return -1 * (target - output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node Class and Instances\n",
    "class Node:\n",
    "    def __init__(self, node_number, node_type, node_level, activation_function, weight, node_value=0):\n",
    "        self.node_number = node_number\n",
    "        self.node_type = node_type\n",
    "        self.node_in_value = node_value # Added for tubes bagian B\n",
    "        self.node_out_value = node_value # For non-input nodes, this value is 0 initially\n",
    "        self.node_level = node_level\n",
    "        self.activation_function = activation_function\n",
    "        self.weight = weight\n",
    "        # Updated for tubes bagian B\n",
    "        self.target_output = 0 # 0 for non-output nodes\n",
    "        self.error = 0\n",
    "        self.derivative_value = 0\n",
    "        self.pending_weight_change = {}\n",
    "    \n",
    "    def getNodeNumber(self):\n",
    "        return self.node_number\n",
    "    \n",
    "    def getNodeType(self):\n",
    "        return self.node_type\n",
    "    \n",
    "    # Modified for tubes bagian B\n",
    "    \n",
    "    def getNodeInValue(self):\n",
    "        return self.node_in_value\n",
    "    \n",
    "    def setNodeInValue(self, node_in_value):\n",
    "        self.node_in_value = node_in_value\n",
    "    \n",
    "    def getNodeOutValue(self):\n",
    "        return self.node_out_value\n",
    "    \n",
    "    def setNodeOutValue(self, node_out_value):\n",
    "        self.node_out_value = node_out_value\n",
    "    \n",
    "    def getNodeLevel(self):\n",
    "        return self.node_level\n",
    "    \n",
    "    def getActivationFunction(self):\n",
    "        return self.activation_function\n",
    "    \n",
    "    def getActivationFunctionValue(self, value):\n",
    "        if self.activation_function == \"linear\":\n",
    "            return linear(value)\n",
    "        elif self.activation_function == \"sigmoid\":\n",
    "            return sigmoid(value)\n",
    "        elif self.activation_function == \"relu\":\n",
    "            return relu(value)\n",
    "        else: # Uses softmax\n",
    "            return softmax(value)\n",
    "    \n",
    "    def getWeight(self):\n",
    "        return self.weight\n",
    "    \n",
    "    def getStrWeight(self):\n",
    "        return str(self.weight)\n",
    "    \n",
    "    def getNextLayerNodeNumbers(self, nodes):\n",
    "        next_layer_nodes = []\n",
    "        for node in nodes:\n",
    "            if node.getNodeLevel() == self.node_level + 1:\n",
    "                next_layer_nodes.append(node.getNodeNumber())\n",
    "        return next_layer_nodes\n",
    "    \n",
    "    # Updated for tubes bagian B\n",
    "\n",
    "    def getError(self):\n",
    "        return self.error\n",
    "    \n",
    "    def getTargetOutput(self):\n",
    "        return self.target_output\n",
    "    \n",
    "    def setTargetOutput(self, target_output):\n",
    "        self.target_output = target_output\n",
    "    \n",
    "    def setError(self, error):\n",
    "        self.error = error\n",
    "\n",
    "    def compareOutput(self, target_output):\n",
    "        self.target_output = target_output\n",
    "        # Also calculate the error\n",
    "        if self.getActivationFunction() != \"softmax\":\n",
    "            self.setError(0.5 * (self.target_output - self.node_out_value) ** 2)\n",
    "        elif self.getActivationFunction() == \"softmax\":\n",
    "            self.setError(-1 * np.log(self.node_out_value))\n",
    "    \n",
    "    def getDerivativeValue(self):\n",
    "        return self.derivative_value\n",
    "    \n",
    "    def setDerivativeValue(self):\n",
    "        if self.getActivationFunction() == \"relu\":\n",
    "            self.derivative_value = derivative_relu(self.node_out_value)\n",
    "        elif self.getActivationFunction() == \"sigmoid\":\n",
    "            self.derivative_value = derivative_sigmoid(self.node_out_value)\n",
    "        elif self.getActivationFunction() == \"linear\":\n",
    "            self.derivative_value = derivative_linear(self.node_out_value)\n",
    "        else: # Uses softmax\n",
    "            isTrueClass = False if self.target_output == 0 else True\n",
    "            self.derivative_value = derivativeSoftmax(self.node_out_value, isTrueClass)\n",
    "    \n",
    "    def updateWeight(self, target_node, learning_rate):\n",
    "        self.weight[target_node.node_number] -= self.pending_weight_change[target_node.node_number]\n",
    "        \n",
    "    def calculate_dE_dOut(self):\n",
    "        if self.node_type == \"output\":\n",
    "            self.dE_dOut = derivative_error_sse(self.target_output, self.node_out_value)\n",
    "        else:\n",
    "            self.dE_dOut = 0\n",
    "        return self.dE_dOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, number_of_layers:int, number_of_nodes:int, nodes:list, \n",
    "                 expected_results:list, stopped_by:str, final_weights:list,\n",
    "                 learning_rate:float, batch_size:int, max_iteration:int, error_threshold:float):\n",
    "        self.number_of_layers = number_of_layers\n",
    "        self.number_of_nodes = number_of_nodes\n",
    "        self.nodes = nodes # We assume that bias are also nodes of value 1\n",
    "        self.expected_results = expected_results\n",
    "        # Updated for tubes bagian B\n",
    "        self.stopped_by = stopped_by\n",
    "        self.final_weights = final_weights\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.max_iteration = max_iteration\n",
    "        self.error_threshold = error_threshold\n",
    "    \n",
    "    def getStoppedBy(self):\n",
    "        return self.stopped_by\n",
    "    \n",
    "    def getFinalWeights(self):\n",
    "        return self.final_weights\n",
    "    \n",
    "    def getLearningRate(self):\n",
    "        return self.learning_rate\n",
    "    \n",
    "    def getBatchSize(self):\n",
    "        return self.batch_size\n",
    "    \n",
    "    def getMaxIteration(self):\n",
    "        return self.max_iteration\n",
    "    \n",
    "    def getErrorThreshold(self):\n",
    "        return self.error_threshold\n",
    "    \n",
    "    def getNumberOfLayers(self):\n",
    "        return self.number_of_layers\n",
    "    \n",
    "    def getNumberOfNodes(self):\n",
    "        return self.number_of_nodes\n",
    "    \n",
    "    def getNodeList(self):\n",
    "        return self.nodes\n",
    "    \n",
    "    def getNodeByIndex(self, index):\n",
    "        return self.nodes[index]\n",
    "    \n",
    "    def setNodeInValueByIndex(self, index, node_value):\n",
    "        self.nodes[index].setNodeInValue(node_value)\n",
    "    \n",
    "    def setNodeOutValueByIndex(self, index, node_value):\n",
    "        self.nodes[index].setNodeOutValue(node_value)\n",
    "    \n",
    "    def getNodeByLevel(self, layer):\n",
    "        nodes = []\n",
    "        for node in self.nodes:\n",
    "            if node.getNodeLevel() == layer:\n",
    "                nodes.append(node)\n",
    "        return nodes\n",
    "    \n",
    "    def getExpectedResults(self):\n",
    "        return self.expected_results\n",
    "\n",
    "    def getCurrentWeights(self):\n",
    "        weights = []\n",
    "        for layer in range(0, self.number_of_layers-1):\n",
    "            nodes = self.getNodeByLevel(layer)\n",
    "            temp_weights = []\n",
    "            for node in nodes:\n",
    "                key_list = list(node.getWeight().keys())\n",
    "                for key in key_list:\n",
    "                    temp_weights.append(node.getWeight()[key])\n",
    "                weights.append(temp_weights)\n",
    "                temp_weights = []\n",
    "        return weights\n",
    "\n",
    "    def getModelInfo(self):\n",
    "        print(\"Number of Layers: \", self.number_of_layers)\n",
    "        print(\"Number of Nodes: \", self.number_of_nodes) # Bias is also counted as a node here\n",
    "        print(\"Nodes: \")\n",
    "        for node in self.nodes:\n",
    "            node.getNodeInfo()\n",
    "    \n",
    "    def printModelSummary(self):\n",
    "        print(\"Model Summary:\")\n",
    "        print(\"---------------------------------------------------\")\n",
    "        print(\"{:^10} | {:^10} | {:^10} | {:^10} | {:^10}\".format(\"Node Number\", \"Node Type\", \"Layer Depth\", \"Activation Function\", \"Weight\"))\n",
    "        for level in range(0,self.number_of_layers+2):\n",
    "            nodes = self.getNodeByLevel(level)\n",
    "            for node in nodes:\n",
    "                print(\"{:^10d} | {:^10s} | {:^10d} | {:^10s} | {:^10s}\".format(\n",
    "                    node.getNodeNumber(), node.getNodeType(), node.getNodeLevel(), node.getActivationFunction(), node.getStrWeight()))\n",
    "        print(\"---------------------------------------------------\")\n",
    "        print(\"Expected Results: \", str(self.expected_results))\n",
    "        print(\"Real Output: \", str(self.getOutputNodeValues()))\n",
    "        print(\"Stopped By: \", self.stopped_by)\n",
    "        print(\"Current Weights: \", self.getCurrentWeights())\n",
    "        print(\"Final (Target) Weights: \", self.final_weights)\n",
    "        print(\"Learning Rate: \", self.learning_rate)\n",
    "        print(\"Batch Size: \", self.batch_size)\n",
    "        print(\"Max Iteration: \", self.max_iteration)\n",
    "        print(\"Error Threshold: \", self.error_threshold)\n",
    "        print(\"\")\n",
    "    \n",
    "    def getInputNodeNumbers(self):\n",
    "        input_nodes = []\n",
    "        for node in self.nodes:\n",
    "            if node.getNodeLevel() == 0 and node.getNodeType() == \"input\":\n",
    "                input_nodes.append(node.getNodeNumber())\n",
    "        return input_nodes\n",
    "    \n",
    "    def getOutputNodeValues(self):\n",
    "        output_nodes = []\n",
    "        for node in self.nodes:\n",
    "            if node.getNodeLevel() == self.number_of_layers - 1:\n",
    "                output_nodes.append(node.getNodeOutValue())\n",
    "        return output_nodes\n",
    "    \n",
    "    def printModelVisualization(self):\n",
    "        edge_list = []\n",
    "        layer_dict = {}\n",
    "        for node in self.nodes:\n",
    "            next_layer_nodes = node.getNextLayerNodeNumbers(self.nodes)\n",
    "            for next_layer_node in next_layer_nodes:\n",
    "                if self.getNodeByIndex(next_layer_node).getNodeType() == \"bias\":\n",
    "                    pass\n",
    "                else:\n",
    "                    edge_pair = (node.getNodeNumber(), next_layer_node)\n",
    "                    if edge_pair not in edge_list:\n",
    "                        edge_list.append(edge_pair)\n",
    "            layer_dict[node.getNodeNumber()] = node.getNodeLevel()\n",
    "        G = nx.Graph(edge_list)\n",
    "        nx.set_node_attributes(G, layer_dict, \"layer\")\n",
    "        pos = nx.multipartite_layout(G, subset_key=\"layer\", align=\"vertical\")\n",
    "        nx.draw(G, pos=pos,with_labels=True, node_size=1000, node_color='skyblue', font_size=10, font_color='white', font_weight='bold')\n",
    "        plt.title(\"Feed-forward Neural Network Model Representation\")\n",
    "        plt.show()\n",
    "    \n",
    "    def getOutputNodeErrorSum(self):\n",
    "        error_sum = 0\n",
    "        for node in self.nodes:\n",
    "            if node.getNodeLevel() == self.number_of_layers - 1:\n",
    "                error_sum += node.getError()\n",
    "        return error_sum\n",
    "    \n",
    "    def updateAllNodeWeights(self):\n",
    "        for node in self.nodes:\n",
    "            next_layer_nodes = node.getNextLayerNodeNumbers(self.nodes)\n",
    "            for next_layer_node in next_layer_nodes:\n",
    "                target_node = self.getNodeByIndex(next_layer_node)\n",
    "                node.updateWeight(target_node, self.learning_rate)\n",
    "    \n",
    "    def getPendingWeightChangePerLayer(self, layer):\n",
    "        pending_weight_change = {}\n",
    "        nodes = self.getNodeByLevel(layer)\n",
    "        for node in nodes:\n",
    "            pending_weight_change[node.getNodeNumber()] = node.pending_weight_change\n",
    "        return pending_weight_change\n",
    "\n",
    "    def exportToJSON(self, pathname):\n",
    "        # data = {}\n",
    "        # data[\"model\"] = []\n",
    "        # for node in self.nodes:\n",
    "        #     node_data = {\n",
    "        #         \"node_number\": node.getNodeNumber(),\n",
    "        #         \"node_type\": node.getNodeType(),\n",
    "        #         \"node_value\": node.getNodeValue(),\n",
    "        #         \"node_level\": node.getNodeLevel(),\n",
    "        #         \"activation_function\": node.getActivationFunction(),\n",
    "        #         \"weight\": node.getWeight()\n",
    "        #     }\n",
    "        #     data[\"model\"].append(node_data)\n",
    "        # data[\"expected_results\"] = self.expected_results\n",
    "        # with open(pathname, 'w') as outfile:\n",
    "        #     json.dump(data, outfile)\n",
    "        # TODO: Ganti implementasi buat bagian B\n",
    "        pass\n",
    "    \n",
    "    def loadJSON(self, pathname):\n",
    "        # with open(pathname) as json_file:\n",
    "        #     data = json.load(json_file)\n",
    "        #     number_of_layers = 0\n",
    "        #     number_of_nodes = 0\n",
    "        #     nodes = []\n",
    "        #     for node in data[\"model\"]:\n",
    "        #         node_instance = Node(node[\"node_number\"], node[\"node_type\"], node[\"node_level\"], node[\"activation_function\"], node[\"weight\"], node[\"node_value\"])\n",
    "        #         nodes.append(node_instance)\n",
    "        #         if node[\"node_level\"] > number_of_layers:\n",
    "        #             number_of_layers = node[\"node_level\"]\n",
    "        #         number_of_nodes += 1\n",
    "        #     expected_results = data[\"expected_results\"]\n",
    "        #     max_sse = data[\"max_sse\"]\n",
    "        #     return Model(number_of_layers, number_of_nodes, nodes, expected_results, max_sse)\n",
    "        # TODO: Ganti implementasi buat bagian B\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readJSON(filename):\n",
    "    nodes = []\n",
    "    file = pd.read_json(filename)\n",
    "    expect = file['expect']\n",
    "    case = file['case']\n",
    "    learning_params = case['learning_parameters']\n",
    "    number_of_layers = len(case['model']['layers']) + 1 # Including input layers\n",
    "    node_counts = [case['model']['input_size']]\n",
    "    for idx in range(0, number_of_layers - 1):\n",
    "        layer = case['model']['layers'][idx]\n",
    "        layer_node_count = layer['number_of_neurons']\n",
    "        node_counts.append(layer_node_count)\n",
    "    sum_per_layer = []\n",
    "    for layer_idx in range(0, number_of_layers - 1):\n",
    "        sum_per_layer.append(sum(node_counts[0:layer_idx+1]) + layer_idx)\n",
    "    # Set node_idx to start counting the nodes from index 0\n",
    "    node_idx = 0\n",
    "    # Set every first node value as bias\n",
    "    set_node_to_bias = True\n",
    "    # Retrieve input values\n",
    "    # input_vals = case['input'][0]\n",
    "    # print(\"Input values: \", input_vals)\n",
    "    # Process input nodes\n",
    "    for node_count in range(case['model']['input_size'] + 1):\n",
    "        node_number = node_idx\n",
    "        node_type = 'bias' if set_node_to_bias else 'input'\n",
    "        node_level = 0\n",
    "        node_value = 1 if set_node_to_bias else 0\n",
    "        activation_function = ''\n",
    "        # Weights info for the input layer is located on the first array of the weights JSON\n",
    "        weights_info = case['initial_weights'][0][node_count]\n",
    "        weights = {}\n",
    "        for next_layer_node_idx in range(node_counts[1]):\n",
    "            weights_idx = -1\n",
    "            if number_of_layers == 2:\n",
    "                weights_idx = next_layer_node_idx + sum_per_layer[0] + 1\n",
    "            elif number_of_layers > 2:\n",
    "                weights_idx = next_layer_node_idx + sum_per_layer[0] + 2\n",
    "            weights[weights_idx] = round(weights_info[next_layer_node_idx], 3)\n",
    "        new_node = Node(node_number, node_type, node_level, activation_function, weights, node_value)\n",
    "        # Set next nodes as non-bias and add 1 to the node_idx\n",
    "        set_node_to_bias = False\n",
    "        node_idx += 1\n",
    "        nodes.append(new_node)\n",
    "    # Process hidden layer nodes\n",
    "    if len(node_counts) > 2: # If there are hidden layers, more than just input and output\n",
    "        # Reset set_node_to_bias to True for each hidden layer\n",
    "        set_node_to_bias = True\n",
    "        for layer_idx in range(len(node_counts) - 1):\n",
    "            if layer_idx == 0:\n",
    "                continue # Input layer has been processed\n",
    "            for node_count in range(node_counts[layer_idx] + 1):\n",
    "                node_number = node_idx\n",
    "                node_type = 'bias' if set_node_to_bias else 'hidden'\n",
    "                node_level = layer_idx\n",
    "                node_value = 1 if set_node_to_bias else 0\n",
    "                activation_function = case['model']['layers'][layer_idx-1]['activation_function']\n",
    "                weights_info = case['initial_weights'][layer_idx][node_count]\n",
    "                weights = {}\n",
    "                for next_layer_node_idx in range(node_counts[layer_idx + 1]):\n",
    "                    weight_idx = -1\n",
    "                    if layer_idx == number_of_layers - 2:\n",
    "                        weight_idx = next_layer_node_idx + sum_per_layer[layer_idx] + 1\n",
    "                    else:\n",
    "                        weight_idx = next_layer_node_idx + sum_per_layer[layer_idx] + 2\n",
    "                    weights[weight_idx] = round(weights_info[next_layer_node_idx], 3)\n",
    "                new_node = Node(node_number, node_type, node_level, activation_function, weights, node_value)\n",
    "                set_node_to_bias = False\n",
    "                node_idx += 1\n",
    "                nodes.append(new_node)\n",
    "            set_node_to_bias = True\n",
    "    # Process output layer nodes\n",
    "    for node_count in range(node_counts[-1]):\n",
    "        node_number = node_idx\n",
    "        node_type = 'output'\n",
    "        node_level = number_of_layers - 1\n",
    "        node_value = 0\n",
    "        activation_function = case['model']['layers'][-1]['activation_function']\n",
    "        weights = {}\n",
    "        new_node = Node(node_number, node_type, node_level, activation_function, weights, node_value)\n",
    "        node_idx += 1\n",
    "        nodes.append(new_node)\n",
    "    # Check nodes results:\n",
    "    # for node in nodes:\n",
    "    #     print(\"Node Info:\")\n",
    "    #     print(\"Node Number: \", node.getNodeNumber())\n",
    "    #     print(\"Node Type: \", node.getNodeType())\n",
    "    #     print(\"Node Level: \", node.getNodeLevel())\n",
    "    #     print(\"Node Out Value: \", node.getNodeOutValue())\n",
    "    #     print(\"Activation Function: \", node.getActivationFunction())\n",
    "    #     print(\"Node weights: \", node.getWeight())\n",
    "    #     print()\n",
    "    # Retrieve expected results:\n",
    "    stopped_by = expect['stopped_by']\n",
    "    final_weights = expect['final_weights']\n",
    "    target = case['target']\n",
    "    # Get additional learning parameters\n",
    "    learning_rate = learning_params['learning_rate']\n",
    "    batch_size = learning_params['batch_size']\n",
    "    max_iteration = learning_params['max_iteration']\n",
    "    error_threshold = learning_params['error_threshold']\n",
    "    # def __init__(self, number_of_layers:int, number_of_nodes:int, nodes:list, \n",
    "                #  expected_results:list, stopped_by:str, final_weights:list,\n",
    "                #  learning_rate:float, batch_size:int, max_iteration:int, error_threshold:float):\n",
    "    result = Model(number_of_layers, sum(node_counts), nodes, target, stopped_by, final_weights, learning_rate, batch_size, max_iteration, error_threshold)\n",
    "    # print(\"Model layers: \", number_of_layers)\n",
    "    # result.getModelInfo()\n",
    "    result.printModelSummary()\n",
    "    # result.printModelVisualization()\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(model, file, batch_count):\n",
    "    # Retrieve expected results\n",
    "    expect = file['expect']\n",
    "    case = file['case']\n",
    "    target = case['target']\n",
    "    # Calculate the error for each output node and set the derivative function\n",
    "    for idx in range(len(target[batch_count])):\n",
    "        output_node = model.getNodeByLevel(model.getNumberOfLayers()-1)[idx]\n",
    "        output_node.compareOutput(target[batch_count][idx])\n",
    "        output_node.setDerivativeValue()\n",
    "    # Calculate the error for each hidden node\n",
    "    for layer in range(model.getNumberOfLayers()-2, 0, -1):\n",
    "        nodes = model.getNodeByLevel(layer)\n",
    "        for node in nodes:\n",
    "            next_layer_nodes = node.getNextLayerNodeNumbers(model.getNodeList())\n",
    "            error = 0\n",
    "            for next_layer_node in next_layer_nodes:\n",
    "                next_node = model.getNodeByIndex(next_layer_node)\n",
    "                error += next_node.getWeight()[node.getNodeNumber()] * next_node.getError()\n",
    "            node.setError(error)\n",
    "            node.setDerivativeValue()\n",
    "            # print(\"Hidden Node \", node.getNodeNumber(), \" Error: \", node.getError(), \" Derivative Value: \", node.getDerivativeValue())\n",
    "    # Update the weights\n",
    "    for layer in range(0, model.getNumberOfLayers()-1):\n",
    "        nodes = model.getNodeByLevel(layer)\n",
    "        for node in nodes:\n",
    "            next_layer_nodes = node.getNextLayerNodeNumbers(model.getNodeList())\n",
    "            for next_layer_node in next_layer_nodes:\n",
    "                next_node = model.getNodeByIndex(next_layer_node)\n",
    "                if node.pending_weight_change.get(next_node.getNodeNumber()) == None:\n",
    "                    node.pending_weight_change[next_node.getNodeNumber()] = 0\n",
    "                # print(\"Next (Target) Node: {}, target output = {}, actual output = {}\".format(next_node.getNodeNumber(), next_node.getTargetOutput(), next_node.getNodeOutValue()))\n",
    "                # print(\"Node {} to target node {}, derivative value (dOut_dNett): {}, dE_dOut: {}, dNett_dW: {}\".format(node.getNodeNumber(), next_node.getNodeNumber(), next_node.getDerivativeValue(), next_node.calculate_dE_dOut(), node.getNodeOutValue()))\n",
    "                weight_change = model.getLearningRate() * next_node.getDerivativeValue() * next_node.calculate_dE_dOut() * node.getNodeOutValue()\n",
    "                # print(\"Node {} to target node {}, weight change: {}\\n\".format(node.getNodeNumber(), next_node.getNodeNumber(), weight_change))\n",
    "                node.pending_weight_change[next_node.getNodeNumber()] += weight_change\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardPass(model, file, iteration_count, backpropagate):\n",
    "    # Fill all input nodes with values and then feed the values to the nodes of the next layer\n",
    "    input_nodes = model.getInputNodeNumbers()\n",
    "    expect = file['expect']\n",
    "    case = file['case']\n",
    "    data = case['input']\n",
    "\n",
    "    batch_size = model.getBatchSize()\n",
    "\n",
    "    for arr_idx in range(0, len(data), batch_size):\n",
    "        final_results = []\n",
    "        for idx in range(arr_idx, arr_idx + batch_size):\n",
    "            data_count = idx - arr_idx\n",
    "            arr = data[idx]\n",
    "            if len(arr) != len(input_nodes):\n",
    "                print(\"Number of input nodes and number of features are not equal\")\n",
    "                sys.exit(1)\n",
    "                \n",
    "            for idx in range(len(arr)):\n",
    "                # print(\"Inserting value {} to input node {}\".format(arr[idx], input_nodes[idx]))\n",
    "                model.setNodeInValueByIndex(input_nodes[idx], arr[idx])\n",
    "                model.setNodeOutValueByIndex(input_nodes[idx], arr[idx])\n",
    "            \n",
    "            # Debug first layer, whether the values are inserted correctly\n",
    "            # for node in model.getNodeByLevel(0):\n",
    "            #     print(\"Node {} has value {}\".format(node.getNodeNumber(), node.getNodeValue()))\n",
    "\n",
    "            for layer in range(0, model.getNumberOfLayers()+1):\n",
    "                # Get all nodes in the layer and then one by one feed the values to the next layer\n",
    "                # At first the values will be based purely on the node's values and its weights\n",
    "                # Then it will be passed to the activation function to get the final value\n",
    "                nodes = model.getNodeByLevel(layer)\n",
    "                # next_node_values stores IN values, not OUT\n",
    "                next_node_values = {}\n",
    "                for node in nodes:\n",
    "                    for next_node_key in node.getWeight().keys():\n",
    "                        if next_node_key not in next_node_values.keys():\n",
    "                            next_node_values[next_node_key] = node.getWeight()[next_node_key] * node.getNodeOutValue()\n",
    "                        else:\n",
    "                            next_node_values[next_node_key] += node.getWeight()[next_node_key] * node.getNodeOutValue()\n",
    "                isSoftmax = False\n",
    "                for next_node_key in next_node_values.keys():\n",
    "                    # print(\"Next node key: \", next_node_key)\n",
    "                    next_node = model.getNodeByIndex(next_node_key)\n",
    "                    next_node_value = next_node_values[next_node_key]\n",
    "                    next_node.setNodeInValue(next_node_value)\n",
    "                    if next_node.getActivationFunction() != \"softmax\" and not isSoftmax:\n",
    "                        isSoftmax = False\n",
    "                        next_node_out_value = next_node.getActivationFunctionValue(next_node_value)\n",
    "                        next_node.setNodeOutValue(next_node_out_value)\n",
    "                        next_node_values[next_node_key] = next_node_out_value\n",
    "                    else:\n",
    "                        next_node_values[next_node_key] = next_node_value\n",
    "                        isSoftmax = True\n",
    "                if isSoftmax:\n",
    "                    # Process all nodes in the layer and then feed the values to that same layer\n",
    "                    process_layer = layer + 1\n",
    "                    nodes = model.getNodeByLevel(process_layer)\n",
    "                    node_numbers_in_order = []\n",
    "                    node_values_in_order = []\n",
    "                    nodes_new_value_pair_key = {}\n",
    "                    for node in nodes:\n",
    "                        node_numbers_in_order.append(node.getNodeNumber())\n",
    "                        node_values_in_order.append(node.getNodeInValue())\n",
    "                        nodes_new_value_pair_key[node.getNodeNumber()] = 0\n",
    "                    node_values_in_order = softmax(node_values_in_order)\n",
    "                    for idx in range(len(node_values_in_order)):\n",
    "                        nodes_new_value_pair_key[node_numbers_in_order[idx]] = node_values_in_order[idx]\n",
    "                    for node in nodes:\n",
    "                        if node.getNodeNumber() in nodes_new_value_pair_key.keys():\n",
    "                            node.setNodeOutValue(nodes_new_value_pair_key[node.getNodeNumber()])\n",
    "                \n",
    "                # Debug the layer, whether the values are inserted and calculated correctly\n",
    "                # for node in model.getNodeByLevel(layer+1):\n",
    "                #     print(\"Node {} has out value {}\".format(node.getNodeNumber(), node.getNodeOutValue()))\n",
    "\n",
    "            # print(model.getOutputNodeValues())\n",
    "            final_results.append(model.getOutputNodeValues())\n",
    "            if backpropagate:\n",
    "                model = backpropagation(model, file, data_count)\n",
    "            print(model.getPendingWeightChangePerLayer(0))\n",
    "        model.updateAllNodeWeights()\n",
    "        print(\"Has updated weights\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(src_name):\n",
    "    model = readJSON(src_name)\n",
    "    file = pd.read_json(src_name)\n",
    "\n",
    "    max_iteration = model.getMaxIteration()\n",
    "    stopped_by = model.getStoppedBy()\n",
    "    \n",
    "    if stopped_by == \"max_iteration\":\n",
    "        for i in range(max_iteration):\n",
    "            model = forwardPass(model, file, i, True)\n",
    "            model.printModelSummary()\n",
    "    elif stopped_by == \"error_threshold\":\n",
    "        iteration_count = 1\n",
    "        while True:\n",
    "            model = forwardPass(model, file, iteration_count, True)\n",
    "            if model.getOutputNodeErrorSum() <= model.getErrorThreshold():\n",
    "                break\n",
    "            model.printModelSummary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "---------------------------------------------------\n",
      "Node Number | Node Type  | Layer Depth | Activation Function |   Weight  \n",
      "    0      |    bias    |     0      |            | {3: 0.1, 4: 0.3, 5: 0.2}\n",
      "    1      |   input    |     0      |            | {3: 0.4, 4: 0.2, 5: -0.7}\n",
      "    2      |   input    |     0      |            | {3: 0.1, 4: -0.8, 5: 0.5}\n",
      "    3      |   output   |     1      |   linear   |     {}    \n",
      "    4      |   output   |     1      |   linear   |     {}    \n",
      "    5      |   output   |     1      |   linear   |     {}    \n",
      "---------------------------------------------------\n",
      "Expected Results:  [[2.0, 0.30000000000000004, -1.9], [1.3, -0.7000000000000001, 0.1]]\n",
      "Real Output:  [0, 0, 0]\n",
      "Stopped By:  max_iteration\n",
      "Current Weights:  [[0.1, 0.3, 0.2], [0.4, 0.2, -0.7], [0.1, -0.8, 0.5]]\n",
      "Final (Target) Weights:  [[[0.22, 0.36, 0.11], [0.64, 0.30000000000000004, -0.89], [0.28, -0.7000000000000001, 0.37]]]\n",
      "Learning Rate:  0.1\n",
      "Batch Size:  2\n",
      "Max Iteration:  1\n",
      "Error Threshold:  0.0\n",
      "\n",
      "{0: {3: -0.05999999999999997, 4: -0.019999999999999997, 5: 0.050000000000000024}, 1: {3: -0.1799999999999999, 4: -0.05999999999999999, 5: 0.15000000000000008}, 2: {3: -0.05999999999999997, 4: -0.019999999999999997, 5: 0.050000000000000024}}\n",
      "{0: {3: -0.11999999999999998, 4: -0.060000000000000005, 5: 0.09000000000000002}, 1: {3: -0.23999999999999994, 4: -0.1, 5: 0.19000000000000009}, 2: {3: -0.18, 4: -0.1, 5: 0.13000000000000003}}\n",
      "Has updated weights\n",
      "Model Summary:\n",
      "---------------------------------------------------\n",
      "Node Number | Node Type  | Layer Depth | Activation Function |   Weight  \n",
      "    0      |    bias    |     0      |            | {3: 0.21999999999999997, 4: 0.36, 5: 0.10999999999999999}\n",
      "    1      |   input    |     0      |            | {3: 0.6399999999999999, 4: 0.30000000000000004, 5: -0.89}\n",
      "    2      |   input    |     0      |            | {3: 0.28, 4: -0.7000000000000001, 5: 0.37}\n",
      "    3      |   output   |     1      |   linear   |     {}    \n",
      "    4      |   output   |     1      |   linear   |     {}    \n",
      "    5      |   output   |     1      |   linear   |     {}    \n",
      "---------------------------------------------------\n",
      "Expected Results:  [[2.0, 0.30000000000000004, -1.9], [1.3, -0.7000000000000001, 0.1]]\n",
      "Real Output:  [0.7, -1.1, 0.5]\n",
      "Stopped By:  max_iteration\n",
      "Current Weights:  [[0.21999999999999997, 0.36, 0.10999999999999999], [0.6399999999999999, 0.30000000000000004, -0.89], [0.28, -0.7000000000000001, 0.37]]\n",
      "Final (Target) Weights:  [[[0.22, 0.36, 0.11], [0.64, 0.30000000000000004, -0.89], [0.28, -0.7000000000000001, 0.37]]]\n",
      "Learning Rate:  0.1\n",
      "Batch Size:  2\n",
      "Max Iteration:  1\n",
      "Error Threshold:  0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test case for linear FFNN\n",
    "src_name = \"testcase/linear.json\"\n",
    "main(src_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test case sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inferenceData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# For Sigmoid model (sigmoid.json)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m src_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtestcase/sigmoid.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[43minferenceData\u001b[49m(src_name, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'inferenceData' is not defined"
     ]
    }
   ],
   "source": [
    "# For Sigmoid model (sigmoid.json)\n",
    "src_name = \"testcase/sigmoid.json\"\n",
    "inferenceData(src_name, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test case linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For linear.json testcase\n",
    "src_name = \"testcase/linear.json\"\n",
    "inferenceData(src_name, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test case relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For ReLU model (relu.json)\n",
    "src_name = \"testcase/relu.json\"\n",
    "inferenceData(src_name, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test case relu di docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For ReLU model (reludocs.json)\n",
    "src_name = \"testcase/reludocs.json\"\n",
    "inferenceData(src_name, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test case softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Softmax model (softmax.json)\n",
    "src_name = \"testcase/softmax.json\"\n",
    "inferenceData(src_name, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test case multilayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Multilayer model (multilayer.json)\n",
    "src_name = \"testcase/multilayer.json\"\n",
    "inferenceData(src_name, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test case multilayer softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Multilayer model (multilayer.json)\n",
    "src_name = \"testcase/multilayer_softmax.json\"\n",
    "inferenceData(src_name, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test case export and load from and to JSON file (multilayer model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilayer_model = inferenceData(\"testcase/multilayer.json\", True)\n",
    "multilayer_model.exportToJSON(\"exports/multilayer_model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model from JSON\n",
    "new_multilayer_model = Model(0, 0, [], [], 0)\n",
    "new_multilayer_model = new_multilayer_model.loadJSON(\"exports/multilayer_model.json\")\n",
    "new_multilayer_model.printModelSummary()\n",
    "new_multilayer_model.printModelVisualization()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
